{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3e9c1403",
      "metadata": {
        "id": "3e9c1403"
      },
      "source": [
        "# Hypergraph Neural Networks\n",
        "\n",
        "This tutorial illustrates what is hypergraph and how to build a Hypergraph Neural Network using DGL's sparse matrix APIs.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dglai/Thewebconf2023-Tutorial/blob/main/Hypergraph%20neural%20networks.ipynb) [![GitHub](https://img.shields.io/badge/-View%20on%20GitHub-181717?logo=github&logoColor=ffffff)](https://github.com/dmlc/dgl/blob/master/notebooks/sparse/hgnn.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9da26f7a",
      "metadata": {
        "id": "9da26f7a",
        "outputId": "1ae3f0a8-72e8-4b70-aeb2-be86ca0cd591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL installed!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "os.environ['DGLBACKEND'] = \"pytorch\"\n",
        "\n",
        "# Uncomment below to install required packages. If the CUDA version is not 11.6,\n",
        "# check the https://www.dgl.ai/pages/start.html to find the supported CUDA\n",
        "# version and corresponding command to install DGL.\n",
        "!pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html > /dev/null\n",
        "#!pip install torchmetrics > /dev/null\n",
        "\n",
        "try:\n",
        "    import dgl\n",
        "    installed = True\n",
        "except ImportError:\n",
        "    installed = False\n",
        "print(\"DGL installed!\" if installed else \"Failed to install DGL!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7184536f",
      "metadata": {
        "id": "7184536f"
      },
      "source": [
        "## Hypergraphs\n",
        "\n",
        "A [hypergraph](https://en.wikipedia.org/wiki/Hypergraph) consists of *nodes* and *hyperedges*.  Contrary to edges in graphs, a *hyperedge* can connect arbitrary number of nodes.  For instance, the following figure shows a hypergraph with 11 nodes and 5 hyperedges drawn in different colors.\n",
        "![](https://data.dgl.ai/tutorial/img/hgnn/hypergraph4.PNG)\n",
        "\n",
        "Hypergraphs are particularly useful when the relationships between data points within the dataset is not binary.  For instance, more than two products can be co-purchased together in an e-commerce system, so the relationship of co-purchase is $n$-ary rather than binary, and therefore it is better described as a hypergraph rather than a normal graph.  Other examples include:\n",
        "* Co-author relationships\n",
        "* Events involving multiple entities\n",
        "\n",
        "A hypergraph is usually characterized by its *incidence matrix* $H$, whose rows represent nodes and columns represent hyperedges.  An entry $H_{ij}$ is 1 if hyperedge $j$ includes node $i$, or 0 otherwise.  For example, the hypergraph in the figure above can be characterized by a $11 \\times 5$ matrix as follows:\n",
        "\n",
        "$$\n",
        "H = \\begin{bmatrix}\n",
        "1 & 0 & 0 & 0 & 0 \\\\\n",
        "1 & 0 & 0 & 0 & 0 \\\\\n",
        "1 & 1 & 0 & 1 & 1 \\\\\n",
        "0 & 0 & 1 & 0 & 0 \\\\\n",
        "0 & 1 & 0 & 0 & 0 \\\\\n",
        "1 & 0 & 1 & 1 & 1 \\\\\n",
        "0 & 0 & 1 & 0 & 0 \\\\\n",
        "0 & 1 & 0 & 1 & 0 \\\\\n",
        "0 & 1 & 0 & 1 & 0 \\\\\n",
        "0 & 0 & 1 & 0 & 1 \\\\\n",
        "0 & 0 & 0 & 0 & 1 \\\\\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "One can construct the hypergraph incidence matrix by specifying two tensors `nodes` and `hyperedges`, where the node ID `nodes[i]` belongs to the hyperedge ID `hyperedges[i]` for all `i`.  In the case above, the incidence matrix can be constructed below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "173bf9a4",
      "metadata": {
        "id": "173bf9a4",
        "outputId": "ab01a250-0d12-4956-e68c-22564fba4cde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 1., 1.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [1., 0., 1., 1., 1.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 1., 0., 1., 0.],\n",
            "        [0., 1., 0., 1., 0.],\n",
            "        [0., 0., 1., 0., 1.],\n",
            "        [0., 0., 0., 0., 1.]])\n"
          ]
        }
      ],
      "source": [
        "import dgl.sparse as dglsp\n",
        "import torch\n",
        "\n",
        "H = dglsp.spmatrix(\n",
        "    torch.LongTensor([[0, 1, 2, 2, 2, 2, 3, 4, 5, 5, 5, 5, 6, 7, 7, 8, 8, 9, 9, 10],\n",
        "                      [0, 0, 0, 1, 3, 4, 2, 1, 0, 2, 3, 4, 2, 1, 3, 1, 3, 2, 4, 4]])\n",
        ")\n",
        "\n",
        "print(H.to_dense())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e49da034",
      "metadata": {
        "id": "e49da034"
      },
      "source": [
        "The degree of a node in a hypergraph is defined as the number of hyperedges including the node.  Similarly, the degree of a hyperedge in a hypergraph is defined as the number of nodes included by the hyperedge.  In the example above, the hyperedge degrees can be computed by the sum of row vectors (i.e. all 4), while the node degree can be computed by the sum of column vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc8c57a2",
      "metadata": {
        "id": "bc8c57a2",
        "outputId": "6a91998d-ae45-437f-8e83-b947b1379933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node degrees tensor([1., 1., 4., 1., 1., 4., 1., 2., 2., 2., 1.])\n",
            "Hyperedge degrees tensor([4., 4., 4., 4., 4.])\n"
          ]
        }
      ],
      "source": [
        "node_degrees = H.sum(1)\n",
        "print(\"Node degrees\", node_degrees)\n",
        "\n",
        "hyperedge_degrees = H.sum(0)\n",
        "print(\"Hyperedge degrees\", hyperedge_degrees)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64d4dd3f",
      "metadata": {
        "id": "64d4dd3f"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "We would like to apply a hypergraph neural network on a co-citation dataset.  The co-citation dataset is based on Cora.  Since Cora is a citation network (i.e. a graph), we would like to construct a hypergraph from it, where the hyperedges represent *co-citations*: for each paper we construct a hyperedge that includes all the other papers it cited, as well as the paper itself.\n",
        "\n",
        "![](https://data.dgl.ai/tutorial/img/hgnn/equiv.PNG)\n",
        "\n",
        "How do we construct the incidence matrix of such a hypergraph from the adjacency matrix of the original graph?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec1113dd",
      "metadata": {
        "id": "ec1113dd"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    dataset = dgl.data.CoraGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    adj = graph.adj().coalesce()\n",
        "\n",
        "    X = graph.ndata['feat']     # node input features\n",
        "    Y = graph.ndata['label']    # node labels\n",
        "    train_mask = graph.ndata[\"train_mask\"]\n",
        "    val_mask = graph.ndata[\"val_mask\"]\n",
        "    test_mask = graph.ndata[\"test_mask\"]\n",
        "\n",
        "    # INSERT YOUR CODE HERE...\n",
        "    H = ...\n",
        "    return H, X, Y, dataset.num_classes, train_mask, val_mask, test_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fa224aa",
      "metadata": {
        "id": "2fa224aa"
      },
      "source": [
        "## Hypergraph Neural Network (HGNN) Layer\n",
        "\n",
        "The [HGNN layer](https://arxiv.org/pdf/1809.09401.pdf) is one of the earliest hypergraph neural network formulations.  Like GNNs, an HGNN aims to learn node representations by combining the topology as well as the features of the local hypergraph neighborhood.  It is also one of the earliest hypergraph message passing networks, where each node's representation is updated with the representations of its local neighborhood.\n",
        "\n",
        "An HGNN layer is defined as:\n",
        "\n",
        "$$f(X^{(l)}, H; W^{(l)}) = \\sigma(L X^{(l)} W^{(l)})$$$$L = D_v^{-1/2} H B D_e^{-1} H^\\top D_v^{-1/2}$$\n",
        "\n",
        "where\n",
        "\n",
        "* $H \\in \\mathbb{R}^{N \\times M}$ is the incidence matrix of hypergraph with $N$ nodes and $M$ hyperedges.\n",
        "* $D_v \\in \\mathbb{R}^{N \\times N}$ is a diagonal matrix representing node degrees, whose $i$-th diagonal element is $\\sum_{j=1}^M H_{ij}$.\n",
        "* $D_e \\in \\mathbb{R}^{M \\times M}$ is a diagonal matrix representing hyperedge degrees, whose $j$-th diagonal element is $\\sum_{i=1}^N H_{ij}$.\n",
        "* $B \\in \\mathbb{R}^{M \\times M}$ is a diagonal matrix representing the hyperedge weights, whose $j$-th diagonal element is the weight of $j$-th hyperedge.  In our example, $B$ is an identity matrix.\n",
        "\n",
        "Extension of the HGNN framework include learning the hyperedge representations as well.  Basically, a node's representation is updated with its incident hyperedges, whereas a hyperedge's representation is updated with its member nodes.  Examples of such framework include\n",
        "* [HGNN+: General Hypergraph Neural Networks (Gao et al.)](https://ieeexplore.ieee.org/document/9795251) (We will go over this if we have extra time)\n",
        "* [Learning over families of sets (Srinivasan et al.)](https://arxiv.org/pdf/2101.07773.pdf)\n",
        "\n",
        "### Exercise\n",
        "\n",
        "Could you implement the `HypergraphConv` module that computes $L X^{(l)} W^{(l)}$ above, given what you have learned in the previous tutorials?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c6274e",
      "metadata": {
        "id": "71c6274e"
      },
      "outputs": [],
      "source": [
        "import dgl.sparse as dglsp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class HypergraphConv(nn.Module):\n",
        "    def __init__(self, H, in_size, out_size):\n",
        "        super().__init__()\n",
        "        # INSERT YOUR CODE HERE...\n",
        "        \n",
        "    def forward(self, X):\n",
        "        # REPLACE WITH YOUR CODE HERE...\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c20621e",
      "metadata": {
        "id": "2c20621e"
      },
      "source": [
        "The following builds a two-layer HGNN from the `HypergraphConv` module above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "924542be",
      "metadata": {
        "id": "924542be"
      },
      "outputs": [],
      "source": [
        "class HGNN(nn.Module):\n",
        "    def __init__(self, H, in_size, out_size, hidden_dims=16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = HypergraphConv(H, in_size, hidden_dims)\n",
        "        self.conv2 = HypergraphConv(H, hidden_dims, out_size)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.conv1(self.dropout(X))\n",
        "        X = F.relu(X)\n",
        "        X = self.conv2(self.dropout(X))\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02860276",
      "metadata": {
        "id": "02860276"
      },
      "source": [
        "## Training and evaluation\n",
        "\n",
        "This tutorial focuses on the node classification task: given the co-citation dataset, as well as the labels of a subset of nodes, predict the labels of the rest of the nodes.  This is akin to semi-supervised node classification on graphs.\n",
        "\n",
        "Other possible downstream tasks on hypergraphs include:\n",
        "\n",
        "* Hyperedge classification/regression: predict the labels of the hyperedges instead of nodes, similar to edge classification.\n",
        "* Hyperedge completion: given an incomplete hyperedge, predict which nodes belong to the hyperedge as well.  This is akin to link prediction on graphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2387583",
      "metadata": {
        "id": "b2387583"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "from torchmetrics.functional import accuracy\n",
        "\n",
        "def train(model, optimizer, X, Y, train_mask):\n",
        "    model.train()\n",
        "    Y_hat = model(X)\n",
        "    loss = F.cross_entropy(Y_hat[train_mask], Y[train_mask])\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "def evaluate(model, X, Y, val_mask, test_mask, num_classes):\n",
        "    model.eval()\n",
        "    Y_hat = model(X)\n",
        "    val_acc = accuracy(\n",
        "        Y_hat[val_mask], Y[val_mask], task=\"multiclass\", num_classes=num_classes\n",
        "    )\n",
        "    test_acc = accuracy(\n",
        "        Y_hat[test_mask],\n",
        "        Y[test_mask],\n",
        "        task=\"multiclass\",\n",
        "        num_classes=num_classes,\n",
        "    )\n",
        "    return val_acc, test_acc\n",
        "\n",
        "\n",
        "H, X, Y, num_classes, train_mask, val_mask, test_mask = load_data()\n",
        "model = HGNN(H, X.shape[1], num_classes)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "with tqdm.trange(500) as tq:\n",
        "    for epoch in tq:\n",
        "        train(model, optimizer, X, Y, train_mask)\n",
        "        val_acc, test_acc = evaluate(\n",
        "            model, X, Y, val_mask, test_mask, num_classes\n",
        "        )\n",
        "        tq.set_postfix(\n",
        "            {\n",
        "                \"Val acc\": f\"{val_acc:.5f}\",\n",
        "                \"Test acc\": f\"{test_acc:.5f}\",\n",
        "            },\n",
        "            refresh=False,\n",
        "        )\n",
        "\n",
        "print(f\"Test acc: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra content: HGNN+\n",
        "\n",
        "HGNN+ is able to produce both node representations and hyperedge representations.  The idea is to update hyperedge representations with member node representations, and update node representations with incident hyperedge representations.  More specifically, it does so in an alternating manner: the hyperedge representations are updated first, followed by node representation updates.\n",
        "\n",
        "The HGNN+ paper provided a simple implementation of the framework above as follows:\n",
        "\n",
        "* The representation of hyperedge $j$ is computed via averaging the member node representations: $z_j \\gets \\frac{1}{|\\{i': i' \\in j\\}|} \\sum_{i': i' \\in j} x_{i'}$.\n",
        "* The representation of a node $i$ is then computed via averaging the incident hyperedge representations followed by a non-linear projection: $x_i \\gets \\sigma \\left(W \\cdot \\frac{1}{|\\{j': i \\in j'\\}|} \\sum_{j': i \\in j'} z_{j'}\\right)$, where $W$ is a trainable parameter matrix.\n",
        "\n",
        "Could you implement the HGNN+ below, excluding the non-linear activation function $\\sigma$?\n",
        "\n",
        "*Hint:* think of how to rewrite the update rules above in matrix form."
      ],
      "metadata": {
        "id": "a0ggHenwldgG"
      },
      "id": "a0ggHenwldgG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Say that the incident matrix is $H \\in \\mathbb{R}^{N \\times E}$ where $N$ is the number of nodes and $E$ is the number of hyperedges.\n",
        "* Hyperedge update: $Z \\gets \\dots$\n",
        "* Node update: $X \\gets \\dots$"
      ],
      "metadata": {
        "id": "xV8pDfDyoEld"
      },
      "id": "xV8pDfDyoEld"
    },
    {
      "cell_type": "code",
      "source": [
        "class HypergraphConvPlus(nn.Module):\n",
        "    def __init__(self, H, in_size, out_size):\n",
        "        super().__init__()\n",
        "        # INSERT YOUR CODE HERE...\n",
        "        \n",
        "    def forward(self, X):\n",
        "        # REPLACE WITH YOUR CODE HERE...\n",
        "        return X"
      ],
      "metadata": {
        "id": "NfeqvXm7leHa"
      },
      "id": "NfeqvXm7leHa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0sww0jiCreBu"
      },
      "id": "0sww0jiCreBu",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SIGN EXERCISE\n",
        "\n",
        "This is one of the exercises for Thewebconf2023.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dglai/Thewebconf2023-Tutorial/blob/master/sign_exercise.ipynb) [![GitHub](https://img.shields.io/badge/-View%20on%20GitHub-181717?logo=github&logoColor=ffffff)](https://github.com/dglai/Thewebconf2023-Tutorial/blob/master/sign_exercise.ipynb)"
      ],
      "metadata": {
        "id": "_iqWrPwxtZr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "os.environ['DGLBACKEND'] = \"pytorch\"\n",
        "\n",
        "# Uncomment below to install required packages. If the CUDA version is not 11.6,\n",
        "# check the https://www.dgl.ai/pages/start.html to find the supported CUDA\n",
        "# version and corresponding command to install DGL.\n",
        "!pip install dgl -f https://data.dgl.ai/wheels/cu118/repo.html > /dev/null\n",
        "\n",
        "try:\n",
        "    import dgl\n",
        "    installed = True\n",
        "except ImportError:\n",
        "    installed = False\n",
        "print(\"DGL installed!\" if installed else \"DGL not found!\")"
      ],
      "metadata": {
        "id": "FTqB360eRvya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise**\n",
        "\n",
        "Use DGL sparse API to implement the SIGN model defined as \n",
        "$$f(X, A, A^2, \\bar{A}, \\bar{A}^2) = σ_1(g(X, A, A^2, \\bar{A}, \\bar{A}^2)Ω)$$ \n",
        "$$g(X, A, A^2, \\bar{A}, \\bar{A}^2) = σ_2([XΘ_0, AXΘ_1, A^2XΘ_2, \\bar{A}XΘ_3, \\bar{A}^2XΘ_4])$$\n",
        "in which $\\bar{A} = \\bar{D}^{-\\frac{1}{2}}(A+I)\\bar{D}^{-\\frac{1}{2}}$, where $I$ is the identity matrix, and $\\bar{D}$ is the diagonal node degree matrix of $(A+I)$.\n",
        "$Θ_x$ and $Ω$ are all learnable dense weight matrix.\n",
        "\n",
        "$σ_1$ and $σ_2$ are non-linear activations (e.g. relu)."
      ],
      "metadata": {
        "id": "vq2C7ZwWp1po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl.data\n",
        "\n",
        "class SIGN(nn.Module):\n",
        "    def __init__(self, in_size, out_size):\n",
        "        super(SIGN, self).__init__()\n",
        "        ...\n",
        "\n",
        "    def forward(self):\n",
        "        ...\n",
        "\n",
        "# Load Cora dataset for training.\n",
        "dataset = dgl.data.CoraGraphDataset()\n",
        "print(\"Number of categories:\", dataset.num_classes)\n",
        "\n",
        "g = dataset[0]\n",
        "in_size = g.ndata[\"feat\"].shape[1]\n",
        "out_size = dataset.num_classes\n",
        "model = SIGN(in_size, out_size)"
      ],
      "metadata": {
        "id": "r-maBV4Ap2bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model and execute the block, such that you can use the following code to train your model."
      ],
      "metadata": {
        "id": "0z1sIiM7p80R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import dgl.data\n",
        "import dgl.function as fn\n",
        "import dgl.sparse as dglsp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train(g, model):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    best_val_acc = 0\n",
        "    best_test_acc = 0\n",
        "\n",
        "    features = g.ndata[\"feat\"]\n",
        "    labels = g.ndata[\"label\"]\n",
        "    train_mask = g.ndata[\"train_mask\"]\n",
        "    val_mask = g.ndata[\"val_mask\"]\n",
        "    test_mask = g.ndata[\"test_mask\"]\n",
        "    A = dglsp.spmatrix(torch.stack(g.edges()))\n",
        "    for e in range(100):\n",
        "        # Forward\n",
        "        logits = model(A, features)\n",
        "\n",
        "        # Compute prediction\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "        # Compute loss\n",
        "        # Note that you should only compute the losses of the nodes in the\n",
        "        # training set.\n",
        "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "\n",
        "        # Compute accuracy on training/validation/test\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "\n",
        "        # Save the best validation accuracy and the corresponding test\n",
        "        # accuracy.\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            info = (\n",
        "                \"In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f})\"\n",
        "                + \", test acc: {:.3f} (best {:.3f})\"\n",
        "            )\n",
        "            print(\n",
        "                info.format(\n",
        "                    e, loss, val_acc, best_val_acc, test_acc, best_test_acc\n",
        "                )\n",
        "            )\n",
        "\n",
        "train(g, model)"
      ],
      "metadata": {
        "id": "rMhwbK_Pp98R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}